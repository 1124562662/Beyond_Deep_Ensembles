{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "MODELS_PATH = \"./data/huggingface\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "from src.log_mock import PrintLog\n",
    "log = PrintLog()\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapi = wandb.Api()\n",
    "runs = wapi.runs(\"bayes/civil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reliability_plot(results):\n",
    "    print(f\"sECE: {results['sece']:.4f}, ECE: {results['ece']:.4f}\")\n",
    "    bins = list(filter(lambda x: x[0] > 0, zip(results[\"bin_confidences\"], results[\"bin_accuracies\"], results[\"bin_counts\"])))\n",
    "\n",
    "    print(\"\\\\begin{tikzpicture}\")\n",
    "    print(\"    \\\\begin{axis}[calstyle, xmin=0, xmax=1, ymin=0, ymax=1]\")\n",
    "    print(\"        \\\\addplot[dashed, color=black] coordinates {(0,0) (1,1)};\")\n",
    "    print(\"        \\\\addplot[calline] coordinates {\" + \" \".join(map(lambda x: f\"({x[0]}, {x[1]})\", bins)) + \"};\")\n",
    "    for conf, acc, count in list(bins):\n",
    "        print(f\"        \\\\node[above, anchor=south west, rotate=60, font=\\\\tiny] at (axis cs:{conf}, 1.0) {{{count}}};\")\n",
    "        print(f\"        \\\\draw[dotted, color=black] (axis cs:{conf}, {acc}) -- (axis cs:{conf}, 1.0);\")\n",
    "    print(\"    \\\\end{axis}\")\n",
    "    print(\"\\\\end{tikzpicture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "def create_plot_data_for_run(run):\n",
    "    lowest_sece = 1\n",
    "    lowest_sece_group = \"None\"\n",
    "    highest_sece = -1\n",
    "    highest_sece_group = \"None\"\n",
    "    worst_acc = 1\n",
    "    worst_acc_group = \"None\"\n",
    "    print(run.name)\n",
    "    for name, results in run.summary[\"test_results\"].items():\n",
    "        if \"toxic\" in name:\n",
    "            if results[\"sece\"] < lowest_sece:\n",
    "                lowest_sece = results[\"sece\"]\n",
    "                lowest_sece_group = name\n",
    "            if results[\"sece\"] > highest_sece:\n",
    "                highest_sece = results[\"sece\"]\n",
    "                highest_sece_group = name\n",
    "            if results[\"accuracy\"] < worst_acc:\n",
    "                worst_acc = results[\"accuracy\"]\n",
    "                worst_acc_group = name\n",
    "\n",
    "    create_reliability_plot(run.summary[\"test_results\"][lowest_sece_group])\n",
    "\n",
    "    model_name = run.name.split(\"-\")[0]\n",
    "    return {\n",
    "        \"model\": model_name + \"-\" + run.name.split(\"-\")[2] if \"drop-rates\" in run.tags else model_name,\n",
    "        \"worst_acc\": worst_acc_group,\n",
    "        \"worst_acc accuracy\": worst_acc, #run.summary[\"test_results\"][\"worst group accuracy\"],\n",
    "        \"worst_acc sece\": run.summary[\"test_results\"][worst_acc_group][\"sece\"],\n",
    "        \"worst_acc ece\": run.summary[\"test_results\"][worst_acc_group][\"ece\"],\n",
    "\n",
    "        \"lowest_sece\": lowest_sece_group,\n",
    "        \"lowest_sece accuracy\": run.summary[\"test_results\"][lowest_sece_group][\"accuracy\"],\n",
    "        \"lowest_sece sece\": lowest_sece,\n",
    "\n",
    "        \"highest_sece\": highest_sece_group,\n",
    "        \"highest_sece accuracy\": run.summary[\"test_results\"][highest_sece_group][\"accuracy\"],\n",
    "        \"highest_sece sece\": highest_sece,\n",
    "\n",
    "        \"all accuracy\": run.summary[\"test_results\"][\"all\"][\"accuracy\"],\n",
    "        \"all sece\": run.summary[\"test_results\"][\"all\"][\"sece\"],\n",
    "        \"all ece\": run.summary[\"test_results\"][\"all\"][\"ece\"],\n",
    "    }\n",
    "\n",
    "def plot(data, value):\n",
    "    plot = px.box(data, x=\"model\", y=value, color=\"model\")\n",
    "    return plot\n",
    "\n",
    "def pareto_plot(data, group, ece=False):\n",
    "    if ece:\n",
    "        plot = px.scatter(data, x=f\"{group} accuracy\", error_x=f\"{group} accuracy_std\", y=f\"{group} ece\", error_y=f\"{group} ece_std\", color=\"model\")\n",
    "    else:\n",
    "        plot = px.scatter(data, x=f\"{group} accuracy\", error_x=f\"{group} accuracy_std\", y=f\"{group} sece\", error_y=f\"{group} sece_std\", color=\"model\")\n",
    "    return plot\n",
    "\n",
    "def build_data(runs):\n",
    "    rows = []\n",
    "    for run in runs:\n",
    "        if dateutil.parser.parse(run.created_at) < datetime.datetime(2023, 3, 10, 10, 0):\n",
    "            continue\n",
    "        if run.state != \"finished\":\n",
    "            continue\n",
    "        if \"old\" in run.tags:\n",
    "            print(run.name)\n",
    "            continue\n",
    "        print(run.summary.keys())\n",
    "        rows.append(create_plot_data_for_run(run))\n",
    "    return pd.DataFrame.from_dict(rows)\n",
    "\n",
    "def aggregate_data(data):\n",
    "    aggregated_data = data.groupby([\"model\"]).agg({\n",
    "        \"model\": \"first\",\n",
    "        \"worst_acc accuracy\": [\"mean\", \"sem\"], \n",
    "        \"worst_acc sece\": [\"mean\", \"sem\"],\n",
    "        \"worst_acc ece\": [\"mean\", \"sem\"],\n",
    "        \"lowest_sece accuracy\": [\"mean\", \"sem\"], \n",
    "        \"lowest_sece sece\": [\"mean\", \"sem\"],\n",
    "        \"highest_sece accuracy\": [\"mean\", \"sem\"], \n",
    "        \"highest_sece sece\": [\"mean\", \"sem\"],\n",
    "        \"all accuracy\": [\"mean\", \"sem\"], \n",
    "        \"all sece\": [\"mean\", \"sem\"],\n",
    "        \"all ece\": [\"mean\", \"sem\"],\n",
    "    })\n",
    "    aggregated_data.columns = [a[0] + \"_std\" if a[1] == \"sem\" else a[0] for a in aggregated_data.columns.to_flat_index()]\n",
    "    aggregated_data[\"worst_acc accuracy_std\"] *= 2.0\n",
    "    aggregated_data[\"worst_acc sece_std\"] *= 2.0\n",
    "    aggregated_data[\"worst_acc ece_std\"] *= 2.0\n",
    "    aggregated_data[\"lowest_sece accuracy_std\"] *= 2.0\n",
    "    aggregated_data[\"lowest_sece sece_std\"] *= 2.0\n",
    "    aggregated_data[\"highest_sece accuracy_std\"] *= 2.0\n",
    "    aggregated_data[\"highest_sece sece_std\"] *= 2.0\n",
    "    aggregated_data[\"all accuracy_std\"] *= 2.0\n",
    "    aggregated_data[\"all sece_std\"] *= 2.0\n",
    "    aggregated_data[\"all ece_std\"] *= 2.0\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = aggregate_data(build_data(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_names = [\n",
    "    (\"map\", \"MAP\"),\n",
    "    (\"map_4\", \"Deep Ensemble\"),\n",
    "    (\"mcd\", \"MCD ($p=0.2$)\"),\n",
    "    (\"mcd-p0.1\", \"MCD ($p=0.1$)\"),\n",
    "    (\"mcd-p0.05\", \"MCD ($p=0.05$)\"),\n",
    "    (\"mcd-p0.01\", \"MCD ($p=0.01$)\"),\n",
    "    (\"mcd_4\", \"MultiMCD ($p=0.2$)\"),\n",
    "    (\"swag\", \"SWAG\"),\n",
    "    (\"swag_4\", \"MultiSWAG\"),\n",
    "    (\"laplace\", \"Laplace\"),\n",
    "    (\"laplace_4\", \"MultiLaplace\"),\n",
    "    (\"bbb\", \"BBB\"),\n",
    "    (\"bbb_4\", \"MultiBBB\"),\n",
    "    (\"rank1\", \"Rank-1 VI\"),\n",
    "    (\"ll_ivon\", \"iVON\"),\n",
    "    (\"ll_ivon_5\", \"MultiiVON\"),\n",
    "    (\"svgd\", \"SVGD\"),\n",
    "    (\"sngp\", \"SNGP\"),\n",
    "]\n",
    "\n",
    "def num(value, std):\n",
    "    return f\"${float(value):.3f} \\\\pm {float(std):.3f}$\"\n",
    "\n",
    "def col_name(name, align):\n",
    "    return f\"\\\\multicolumn{{1}}{{{align}}}{{{name}}}\"\n",
    "\n",
    "def create_table(data, prefix):\n",
    "    print(\"\\\\begin{tabular}{l|rrr}\")\n",
    "    print(f\"    {col_name('Model', 'l')} & {col_name('Accuracy', 'c')} & {col_name('ECE', 'c')} & {col_name('sECE', 'c')} \\\\\\\\\")\n",
    "    print(\"    \\\\hline\")\n",
    "    for algo, name in algo_names:\n",
    "        row = data[data[\"model\"] == algo]\n",
    "        print(f\"    {name} & {num(row[prefix + ' accuracy'], row[prefix + ' accuracy_std'])} & {num(row[prefix + ' ece'], row[prefix + ' ece_std'])} & {num(row[prefix + ' sece'], row[prefix + ' sece_std'])} \\\\\\\\\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "create_table(data, \"worst_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sep=\",\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_plot(data, \"worst_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_plot(data, \"worst_acc\", ece=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_plot(data, \"lowest_sece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_plot(data, \"highest_sece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_names = [\n",
    "    (\"map\", \"MAP\"),\n",
    "    (\"map_4\", \"Deep Ensemble\"),\n",
    "    (\"mcd\", \"MCD ($p=0.2$)\"),\n",
    "    (\"mcd-p0.1\", \"MCD ($p=0.1$)\"),\n",
    "    (\"mcd-p0.05\", \"MCD ($p=0.05$)\"),\n",
    "    (\"mcd-p0.01\", \"MCD ($p=0.01$)\"),\n",
    "    (\"mcd_4\", \"MultiMCD ($p=0.2$)\"),\n",
    "    (\"swag\", \"SWAG\"),\n",
    "    (\"swag_4\", \"MultiSWAG\"),\n",
    "    # (\"swag_ll-1\", \"LL SWAG\"),\n",
    "    (\"laplace\", \"LL Laplace\"),\n",
    "    (\"laplace_4\", \"LL MultiLaplace\"),\n",
    "    (\"bbb\", \"LL BBB\"),\n",
    "    (\"bbb_4\", \"LL MultiBBB\"),\n",
    "    (\"rank1\", \"Rank-1 VI\"),\n",
    "    (\"ll_ivon\", \"LL iVON\"),\n",
    "    (\"ll_ivon_5\", \"LL MultiiVON\"),\n",
    "    (\"svgd\", \"SVGD\"),\n",
    "    (\"sngp\", \"SNGP\"),\n",
    "]\n",
    "\n",
    "def num(value, std, best=None, ty=None):\n",
    "    value = float(value)\n",
    "    std = float(std)\n",
    "    num_string = f\"{value:.3f} \\\\pm {std:.3f}\"\n",
    "\n",
    "    if best is None or ty is None:\n",
    "        return f\"${num_string}$\"\n",
    "\n",
    "    if ty == \"max\":\n",
    "        if value >= best:\n",
    "            num_string = f\"\\\\bm{{{num_string}}}\"\n",
    "    elif ty == \"min\":\n",
    "        if value <= best:\n",
    "            num_string = f\"\\\\bm{{{num_string}}}\"\n",
    "    elif ty == \"zero\":\n",
    "        if abs(value) <= best:\n",
    "            num_string = f\"\\\\bm{{{num_string}}}\"\n",
    "    return f\"${num_string}$\"\n",
    "\n",
    "def col_name(name, align):\n",
    "    return f\"\\\\multicolumn{{1}}{{{align}}}{{{name}}}\"\n",
    "\n",
    "def create_table(data, prefix):\n",
    "    print(\"\\\\begin{tabular}{l|rrrrrr}\")\n",
    "    print(f\"    {col_name('Model', 'l')} & {col_name('WG Accuracy', 'c')} & {col_name('WG ECE', 'c')} & {col_name('WG sECE', 'c')} & {col_name('Avg Accuracy', 'c')} & {col_name('Avg ECE', 'c')} & {col_name('Avg sECE', 'c')} \\\\\\\\\")\n",
    "    print(\"    \\\\hline\")\n",
    "\n",
    "    best_acc, best_acc_std = 0, 0\n",
    "    best_ece, best_ece_std = 1000, 0\n",
    "    best_sece, best_sece_std = 1000, 0\n",
    "    best_avg_acc, best_avg_acc_std = 0, 0\n",
    "    best_avg_ece, best_avg_ece_std = 1000, 0\n",
    "    best_avg_sece, best_avg_sece_std = 1000, 0\n",
    "\n",
    "    for algo, name in algo_names:\n",
    "        row = data[data[\"model\"] == algo]\n",
    "\n",
    "        if float(row[prefix + \"worst_acc accuracy\"]) > best_acc:\n",
    "            best_acc = float(row[prefix + \"worst_acc accuracy\"])\n",
    "            best_acc_std = float(row[prefix + \"worst_acc accuracy_std\"])\n",
    "        \n",
    "        if float(row[prefix + \"worst_acc ece\"]) < best_ece:\n",
    "            best_ece = float(row[prefix + \"worst_acc ece\"])\n",
    "            best_ece_std = float(row[prefix + \"worst_acc ece_std\"])\n",
    "        \n",
    "        if abs(float(row[prefix + \"worst_acc sece\"])) < best_sece:\n",
    "            best_sece = abs(float(row[prefix + \"worst_acc sece\"]))\n",
    "            best_sece_std = float(row[prefix + \"worst_acc sece_std\"])\n",
    "        \n",
    "        if float(row[prefix + \"all accuracy\"]) > best_avg_acc:\n",
    "            best_avg_acc = float(row[prefix + \"all accuracy\"])\n",
    "            best_avg_acc_std = float(row[prefix + \"all accuracy_std\"])\n",
    "        \n",
    "        if float(row[prefix + \"all ece\"]) < best_avg_ece:\n",
    "            best_avg_ece = float(row[prefix + \"all ece\"])\n",
    "            best_avg_ece_std = float(row[prefix + \"all ece_std\"])\n",
    "        \n",
    "        if abs(float(row[prefix + \"all sece\"])) < best_avg_sece:\n",
    "            best_avg_sece = abs(float(row[prefix + \"all sece\"]))\n",
    "            best_avg_sece_std = float(row[prefix + \"all sece_std\"])\n",
    "\n",
    "    best_acc -= best_acc_std\n",
    "    best_ece += best_ece_std\n",
    "    best_sece = abs(best_sece) + best_sece_std\n",
    "\n",
    "    best_avg_acc -= best_avg_acc_std\n",
    "    best_avg_ece += best_avg_ece_std\n",
    "    best_avg_sece = abs(best_avg_sece) + best_avg_sece_std\n",
    "\n",
    "    for algo, name in algo_names:\n",
    "        row = data[data[\"model\"] == algo]\n",
    "        print(f\"    {name} & {num(row[prefix + 'worst_acc accuracy'], row[prefix + 'worst_acc accuracy_std'], best_acc, 'max')} & {num(row[prefix + 'worst_acc ece'], row[prefix + 'worst_acc ece_std'], best_ece, 'min')} & {num(row[prefix + 'worst_acc sece'], row[prefix + 'worst_acc sece_std'], best_sece, 'zero')} & {num(row[prefix + 'all accuracy'], row[prefix + 'all accuracy_std'], best_avg_acc, 'max')} & {num(row[prefix + 'all ece'], row[prefix + 'all ece_std'], best_avg_ece, 'min')} & {num(row[prefix + 'all sece'], row[prefix + 'all sece_std'], best_avg_sece, 'zero')} \\\\\\\\\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "create_table(data, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e9c95055558620b86d9020eccd072ae63a5e4d40bac5aeb5a6ac17e5908658f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
