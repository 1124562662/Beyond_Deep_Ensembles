{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "from src.log_mock import PrintLog\n",
    "log = PrintLog()\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapi = wandb.Api()\n",
    "runs = wapi.runs(\"bayes/iwildcam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in enumerate(runs):\n",
    "    print(i, run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reliability_plot(run, results_name):\n",
    "    results = run.summary[results_name]\n",
    "    print(f\"sECE: {results['sece']:.4f}, ECE: {results['ece']:.4f}\")\n",
    "    bins = list(filter(lambda x: x[0] > 0, zip(results[\"bin_confidences\"], results[\"bin_accuracies\"], results[\"bin_counts\"])))\n",
    "\n",
    "    print(\"\\\\begin{tikzpicture}\")\n",
    "    print(\"    \\\\begin{axis}[calstyle, xmin=0, xmax=1, ymin=0, ymax=1]\")\n",
    "    print(\"        \\\\addplot[dashed, color=black] coordinates {(0,0) (1,1)};\")\n",
    "    print(\"        \\\\addplot[calline] coordinates {\" + \" \".join(map(lambda x: f\"({x[0]}, {x[1]})\", bins)) + \"};\")\n",
    "    for conf, acc, count in list(bins):\n",
    "        print(f\"        \\\\node[above, anchor=south west, rotate=60, font=\\\\tiny] at (axis cs:{conf}, 1.0) {{{count}}};\")\n",
    "        print(f\"        \\\\draw[dotted, color=black] (axis cs:{conf}, {acc}) -- (axis cs:{conf}, 1.0);\")\n",
    "    print(\"    \\\\end{axis}\")\n",
    "    print(\"\\\\end{tikzpicture}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import dateutil\n",
    "import datetime\n",
    "\n",
    "def create_plot_data_for_run(run):\n",
    "    parts = run.name.split(\"-\")\n",
    "    if len(parts) > 2:\n",
    "        model_name = parts[0] + \"-\" + parts[1]\n",
    "    else:\n",
    "        model_name = parts[0]\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": run.summary[\"test_results\"][\"accuracy\"],\n",
    "        \"macro f1\": run.summary[\"test_results\"][\"macro_f1\"],\n",
    "        \"log likelihood\": run.summary[\"test_results\"][\"log_likelihood\"],\n",
    "        \"ece\": run.summary[\"test_results\"][\"ece\"],\n",
    "        \"sece\": run.summary[\"test_results\"][\"sece\"],\n",
    "        \"id_val accuracy\": run.summary[\"id_val_results\"][\"accuracy\"],\n",
    "        \"id_val macro f1\": run.summary[\"id_val_results\"][\"macro_f1\"],\n",
    "        \"id_val log likelihood\": run.summary[\"id_val_results\"][\"log_likelihood\"],\n",
    "        \"id_val ece\": run.summary[\"id_val_results\"][\"ece\"],\n",
    "        \"id_val sece\": run.summary[\"id_val_results\"][\"sece\"],\n",
    "    }\n",
    "\n",
    "def plot(data, value):\n",
    "    plot = px.box(data, x=\"model\", y=value, color=\"model\")\n",
    "    return plot\n",
    "\n",
    "def pareto_plot(data, x, y):\n",
    "    plot = px.scatter(data, x=x, error_x=f\"{x}_std\", y=y, error_y=f\"{y}_std\", color=\"model\")\n",
    "    return plot\n",
    "\n",
    "def build_data(runs):\n",
    "    rows = []\n",
    "    for run in runs:\n",
    "        if dateutil.parser.parse(run.created_at) < datetime.datetime(2023, 3, 10, 10, 0):\n",
    "            continue\n",
    "        if run.state != \"finished\":\n",
    "            continue\n",
    "        if \"old\" in run.tags:\n",
    "            print(\"Skipping old run \" + run.name)\n",
    "            continue\n",
    "        if \"test_results\" not in run.summary:\n",
    "            print(\"Skipping crashed run \" + run.name)\n",
    "            continue\n",
    "        rows.append(create_plot_data_for_run(run))\n",
    "    return pd.DataFrame.from_dict(rows)\n",
    "\n",
    "def aggregate_data(data):\n",
    "    aggregated_data = data.groupby([\"model\"]).agg({\n",
    "        \"model\": \"first\",\n",
    "        \"accuracy\": [\"mean\", \"sem\"], \n",
    "        \"macro f1\": [\"mean\", \"sem\"], \n",
    "        \"log likelihood\": [\"mean\", \"sem\"], \n",
    "        \"sece\": [\"mean\", \"sem\"],\n",
    "        \"ece\": [\"mean\", \"sem\"],\n",
    "        \"id_val accuracy\": [\"mean\", \"sem\"], \n",
    "        \"id_val macro f1\": [\"mean\", \"sem\"], \n",
    "        \"id_val log likelihood\": [\"mean\", \"sem\"], \n",
    "        \"id_val sece\": [\"mean\", \"sem\"],\n",
    "        \"id_val ece\": [\"mean\", \"sem\"],\n",
    "    })\n",
    "    aggregated_data.columns = [a[0] + \"_std\" if a[1] == \"sem\" else a[0] for a in aggregated_data.columns.to_flat_index()]\n",
    "    aggregated_data[\"accuracy_std\"] *= 2\n",
    "    aggregated_data[\"macro f1_std\"] *= 2\n",
    "    aggregated_data[\"log likelihood_std\"] *= 2\n",
    "    aggregated_data[\"sece_std\"] *= 2\n",
    "    aggregated_data[\"ece_std\"] *= 2\n",
    "    aggregated_data[\"id_val accuracy_std\"] *= 2\n",
    "    aggregated_data[\"id_val macro f1_std\"] *= 2\n",
    "    aggregated_data[\"id_val log likelihood_std\"] *= 2\n",
    "    aggregated_data[\"id_val sece_std\"] *= 2\n",
    "    aggregated_data[\"id_val ece_std\"] *= 2\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = aggregate_data(build_data(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_names = [\n",
    "    (\"map-1\", \"MAP\"),\n",
    "    (\"map_5\", \"Deep Ensemble\"),\n",
    "    (\"mcd-1\", \"MCD\"),\n",
    "    (\"mcd_5\", \"MultiMCD\"),\n",
    "    (\"swag-1\", \"SWAG\"),\n",
    "    (\"swag_5\", \"MultiSWAG\"),\n",
    "    (\"swag_ll-1\", \"LL SWAG\"),\n",
    "    (\"laplace-1\", \"LL Laplace\"),\n",
    "    (\"laplace_5\", \"LL MultiLaplace\"),\n",
    "    (\"bbb-1\", \"LL BBB\"),\n",
    "    (\"bbb_5\", \"LL MultiBBB\"),\n",
    "    (\"rank1-1\", \"Rank-1 VI\"),\n",
    "    (\"ll_ivon-1\", \"LL iVON\"),\n",
    "    (\"ll_ivon_5\", \"LL MultiiVON\"),\n",
    "    (\"svgd-1\", \"SVGD\"),\n",
    "    (\"ll_svgd-1\", \"LL SVGD\"),\n",
    "    (\"sngp\", \"SNGP\"),\n",
    "]\n",
    "\n",
    "def num(value, std, best=None, ty=None):\n",
    "    value = float(value)\n",
    "    std = float(std)\n",
    "    num_string = f\"{value:.3f} \\\\pm {std:.3f}\"\n",
    "\n",
    "    if best is None or ty is None:\n",
    "        return f\"${num_string}$\"\n",
    "\n",
    "    if ty == \"max\":\n",
    "        if value >= best:\n",
    "            num_string = f\"\\\\bm{{{num_string}}}\"\n",
    "    elif ty == \"min\":\n",
    "        if value <= best:\n",
    "            num_string = f\"\\\\bm{{{num_string}}}\"\n",
    "    elif ty == \"zero\":\n",
    "        if abs(value) <= best:\n",
    "            num_string = f\"\\\\bm{{{num_string}}}\"\n",
    "    return f\"${num_string}$\"\n",
    "\n",
    "def col_name(name, align):\n",
    "    return f\"\\\\multicolumn{{1}}{{{align}}}{{{name}}}\"\n",
    "\n",
    "def create_table(data, prefix):\n",
    "    print(\"\\\\begin{tabular}{l|rrrr}\")\n",
    "    print(f\"    {col_name('Model', 'l')} & {col_name('Macro F1 Score', 'c')} & {col_name('Accuracy', 'c')} & {col_name('ECE', 'c')} & {col_name('sECE', 'c')} \\\\\\\\\")\n",
    "    print(\"    \\\\hline\")\n",
    "\n",
    "    best_f1, best_f1_std = 0, 0\n",
    "    best_acc, best_acc_std = 0, 0\n",
    "    best_ece, best_ece_std = 1000, 0\n",
    "    best_sece, best_sece_std = 1000, 0\n",
    "\n",
    "    for algo, name in algo_names:\n",
    "        row = data[data[\"model\"] == algo]\n",
    "        \n",
    "        if float(row[prefix + \"macro f1\"]) > best_f1:\n",
    "            best_f1 = float(row[prefix + \"macro f1\"])\n",
    "            best_f1_std = float(row[prefix + \"macro f1_std\"])\n",
    "        \n",
    "        if float(row[prefix + \"accuracy\"]) > best_acc:\n",
    "            best_acc = float(row[prefix + \"accuracy\"])\n",
    "            best_acc_std = float(row[prefix + \"accuracy_std\"])\n",
    "        \n",
    "        if float(row[prefix + \"ece\"]) < best_ece:\n",
    "            best_ece = float(row[prefix + \"ece\"])\n",
    "            best_ece_std = float(row[prefix + \"ece_std\"])\n",
    "        \n",
    "        if abs(float(row[prefix + \"sece\"])) < best_sece:\n",
    "            best_sece = abs(float(row[prefix + \"sece\"]))\n",
    "            best_sece_std = float(row[prefix + \"sece_std\"])\n",
    "\n",
    "    best_f1 -= best_f1_std\n",
    "    best_acc -= best_acc_std\n",
    "    best_ece += best_ece_std\n",
    "    best_sece = abs(best_sece) + best_sece_std\n",
    "\n",
    "    for algo, name in algo_names:\n",
    "        row = data[data[\"model\"] == algo]\n",
    "        print(f\"    {name} & {num(row[prefix + 'macro f1'], row[prefix + 'macro f1_std'], best_f1, 'max')} & {num(row[prefix + 'accuracy'], row[prefix + 'accuracy_std'], best_acc, 'max')} & {num(row[prefix + 'ece'], row[prefix + 'ece_std'], best_ece, 'min')} & {num(row[prefix + 'sece'], row[prefix + 'sece_std'], best_sece, 'zero')} \\\\\\\\\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "create_table(data, \"id_val \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sep=\",\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_plot(data, \"macro f1\", \"sece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_plot(data, \"id_val macro f1\", \"id_val sece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e9c95055558620b86d9020eccd072ae63a5e4d40bac5aeb5a6ac17e5908658f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
